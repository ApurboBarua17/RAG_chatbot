# RAG Chatbot (PDF-based Retrieval-Augmented Generation)

This project implements a **Retrieval-Augmented Generation (RAG)** chatbot that ingests a user-uploaded PDF, indexes its content, and answers free-form questions using [IBM Watsonx Foundation Models](https://www.ibm.com/cloud/watsonx) with LangChain orchestration, all wrapped in a simple [Gradio](https://gradio.app/) web interface.

---

## ğŸš€ Features

- **PDF Ingestion**: Upload a PDF file, which is split into chunks for efficient retrieval.  
- **Vector Indexing**: Uses **Chroma** as an in-memory vector store for semantic search.  
- **Embeddings**: Generates embeddings with Watsonx Embeddings service (`ibm/slate-125m-english-rtrvr`).  
- **LLM Generation**: Answers queries using Watsonx LLM (`mistralai/mixtral-8x7b-instruct-v01`).  
- **Simple UI**: Gradio interface for file upload and chat-like Q&A.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ main_project.py      # RAG chatbot application
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # This setup guide
```

---

## ğŸ”§ Prerequisites

1. **Python 3.8+**  
2. **IBM Cloud API Key** with access to Watsonx Foundation Models.  
3. **Internet access** for calling IBM Watsonx endpoints.

---

## âš™ï¸ Environment Setup

1. **Clone the repo**  
   ```bash
   git clone https://github.com/your-org/rag-chatbot.git
   cd rag-chatbot
   ```

2. **Install dependencies**  
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure IBM credentials**  
   Create environment variables (or export them in your shell):

   ```bash
   export WATSONX_APIKEY="YOUR_IBM_CLOUD_API_KEY"
   export WATSONX_URL="https://us-south.ml.cloud.ibm.com"
   export WATSONX_PROJECT="skills-network"
   ```

   > The code picks up credentials via `Credentials.from_environment()`.  
   > Alternatively, instantiate `Credentials(apikey=..., url=...)` in code.

---

## ğŸƒâ€â™‚ï¸ Running the Chatbot

```bash
python main_project.py
```

- By default, Gradio will launch at `http://localhost:7860/`.  
- You can optionally pass `share=True` in `launch()` to get a public URL.

---

## ğŸ’¡ Usage

1. **Upload** a PDF document.  
2. **Enter** your query in the text box.  
3. **Receive** an answer generated by the RAG pipeline.

---

## ğŸ”­ Customization

- **Chunk Size / Overlap**: Adjust in `RecursiveCharacterTextSplitter`.  
- **LLM Model & Parameters**: Modify `get_llm()` for a different model or temperature.  
- **Embedding Model**: Change `watsonx_embedding()` to another embeddings endpoint.

---

## ğŸ“ License

This project is released under the **MIT License**.  
Feel free to fork, modify, and share!  
